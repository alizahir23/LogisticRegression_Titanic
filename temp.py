# Import necessary libraries for data handling and visualizationimport pandas as pdimport numpy as npimport matplotlib.pyplot as pltimport seaborn as sns# Importing machine learning functionsfrom sklearn.model_selection import train_test_splitfrom sklearn.linear_model import LogisticRegressionfrom sklearn.metrics import confusion_matrix, accuracy_score# Load the Titanic datasettrain = pd.read_csv('Titanic-Dataset.csv')# Visualizing missing data in the datasetplt.figure(figsize=(5,5))sns.heatmap(train.isnull(), cmap='viridas')plt.title("Heatmap of Missing Values in Titanic Dataset")plt.show()# Visualize the count of survivors in the Titanicplt.figure(figsize=(5,5))sns.countplot(x='Survived', data=train)plt.title("Count of Survivors in Titanic")plt.show()# Visualize survival count by genderplt.figure(figsize=(5,5))sns.countplot(x='Survived', hue='Sex', data=train)plt.title("Survival Count by Gender")plt.show()# Visualize survival count by passenger classplt.figure(figsize=(5,5))sns.countplot(x='Survived', hue='Pclass', data=train)plt.title("Survival Count by Passenger Class")plt.show()# Distribution of age among the passengers, excluding missing valuesplt.figure(figsize=(10,5))sns.distplot(train['Age'].dropna(), bins=80)plt.title("Age Distribution Among Passengers")plt.show()# Function to impute missing age values based on passenger classdef compute_age(cols):    Age, Pclass = cols        if pd.isnull(Age):        return {1: 37, 2: 29, 3: 24}[Pclass]    return Age# Apply function to impute agetrain['Age'] = train[['Age', 'Pclass']].apply(compute_age, axis=1)# Remove the 'Cabin' column from the datasettrain.drop('Cabin', axis=1, inplace=True)# Remove any remaining rows with missing valuestrain.dropna(inplace=True)# Checking again for any remaining missing valuesplt.figure(figsize=(5,5))sns.heatmap(train.isnull(), cmap='viridis')plt.title("Final Heatmap of Missing Values After Cleaning")plt.show()# Convert categorical variables into dummy/indicator variablessex = pd.get_dummies(train['Sex'], drop_first=True)embarked = pd.get_dummies(train['Embarked'], drop_first=True)# Drop redundant or unneeded columnstrain.drop(['Ticket', 'Name', 'Sex', 'Embarked'], axis=1, inplace=True)# Concatenate dummy variables with main dataframetrain = pd.concat([train, sex, embarked], axis=1)# Split the data into training and testing setsX_train, X_test, y_train, y_test = train_test_split(    train.drop(['Survived'], axis=1), train['Survived'], test_size=0.30, random_state=30)# Initialize and train the Logistic Regression modellogModel = LogisticRegression(max_iter=1000)  # Increased max_iter to ensure convergencelogModel.fit(X_train, y_train)# Make predictions on the test setpredictions = logModel.predict(X_test)# Evaluate the model using confusion matrix and accuracy scoreaccuracy = confusion_matrix(y_test, predictions)print("Accuracy Score:", accuracy_score(y_test, predictions))